{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from pandas) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seaborn\n",
      "  Using cached seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from seaborn) (1.26.4)\n",
      "Requirement already satisfied: pandas>=1.2 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from seaborn) (2.2.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from seaborn) (3.9.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.1.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from pandas>=1.2->seaborn) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n",
      "Using cached seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Installing collected packages: seaborn\n",
      "Successfully installed seaborn-0.13.2\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations\n",
      "  Downloading albumentations-1.4.14-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: numpy>=1.24.4 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from albumentations) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.10.0 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from albumentations) (1.14.1)\n",
      "Collecting scikit-image>=0.21.0 (from albumentations)\n",
      "  Downloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: PyYAML in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from albumentations) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.9.0 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from albumentations) (4.11.0)\n",
      "Collecting pydantic>=2.7.0 (from albumentations)\n",
      "  Using cached pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "Collecting albucore>=0.0.13 (from albumentations)\n",
      "  Downloading albucore-0.0.14-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting eval-type-backport (from albumentations)\n",
      "  Downloading eval_type_backport-0.2.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opencv-python-headless>=4.9.0.80 (from albumentations)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting annotated-types>=0.4.0 (from pydantic>=2.7.0->albumentations)\n",
      "  Using cached annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic>=2.7.0->albumentations)\n",
      "  Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: networkx>=2.8 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (3.3)\n",
      "Requirement already satisfied: pillow>=9.1 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (10.4.0)\n",
      "Collecting imageio>=2.33 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading imageio-2.35.1-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tifffile>=2022.8.12 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading tifffile-2024.8.28-py3-none-any.whl.metadata (31 kB)\n",
      "Requirement already satisfied: packaging>=21 in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (from scikit-image>=0.21.0->albumentations) (24.1)\n",
      "Collecting lazy-loader>=0.4 (from scikit-image>=0.21.0->albumentations)\n",
      "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Downloading albumentations-1.4.14-py3-none-any.whl (177 kB)\n",
      "Downloading albucore-0.0.14-py3-none-any.whl (8.5 kB)\n",
      "Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "Downloading pydantic_core-2.20.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scikit_image-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.9/14.9 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading eval_type_backport-0.2.0-py3-none-any.whl (5.9 kB)\n",
      "Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading imageio-2.35.1-py3-none-any.whl (315 kB)\n",
      "Downloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading tifffile-2024.8.28-py3-none-any.whl (226 kB)\n",
      "Installing collected packages: tifffile, pydantic-core, opencv-python-headless, lazy-loader, imageio, eval-type-backport, annotated-types, scikit-image, pydantic, albucore, albumentations\n",
      "Successfully installed albucore-0.0.14 albumentations-1.4.14 annotated-types-0.7.0 eval-type-backport-0.2.0 imageio-2.35.1 lazy-loader-0.4 opencv-python-headless-4.10.0.84 pydantic-2.8.2 pydantic-core-2.20.1 scikit-image-0.24.0 tifffile-2024.8.28\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: compose in /home/downtown/miniconda3/envs/aug_env/lib/python3.11/site-packages (1.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install compose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import albumentations as A\n",
    "from torchvision.transforms import ToTensor, Compose, Grayscale\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from torchvision.io import read_image\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 경로 설정\n",
    "data_dir = \"/home/downtown/new_folder/deep-learning/module/module-1/chest_xray\"\n",
    "train_dir = os.path.join(data_dir, \"train\")\n",
    "test_dir = os.path.join(data_dir, \"test\")\n",
    "\n",
    "# 데이터프레임 생성 함수 정의\n",
    "def create_dataframe(data_dir):\n",
    "    image_paths = glob.glob(f\"{data_dir}/*/*\")\n",
    "    data = {'image_path': [], 'label': []}\n",
    "    for path in image_paths:\n",
    "        if 'NORMAL' in path:\n",
    "            data['image_path'].append(path)\n",
    "            data['label'].append(0)  # NORMAL -> 0\n",
    "        elif 'PNEUMONIA' in path:\n",
    "            data['image_path'].append(path)\n",
    "            data['label'].append(1)  # PNEUMONIA -> 1\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Train과 Test 데이터프레임 생성\n",
    "train_df = create_dataframe(train_dir)\n",
    "test_df = create_dataframe(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 이미지 파일 수: 5216\n",
      "Test 이미지 파일 수: 640\n"
     ]
    }
   ],
   "source": [
    "# 이미지 파일 경로 확인\n",
    "print(\"Train 이미지 파일 수:\", len(glob.glob(f\"{train_dir}/*/*\")))\n",
    "print(\"Test 이미지 파일 수:\", len(glob.glob(f\"{test_dir}/*/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 클래스 정의\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.iloc[idx, 0]\n",
    "        image = Image.open(img_path).convert(\"RGB\")  # 이미지를 RGB로 로드\n",
    "        label = self.df.iloc[idx, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = np.array(image)  # PIL 이미지를 NumPy 배열로 변환\n",
    "            augmented = self.transform(image=image)  # 변환 적용\n",
    "            image = augmented['image']\n",
    "        \n",
    "        # 추가 변환: 명시적으로 그레이스케일로 변환\n",
    "        if image.shape[2] == 3:  # 만약 3채널이라면\n",
    "            image = Image.fromarray((image * 255).astype(np.uint8)).convert('L')  # float32에서 uint8로 변환 후 그레이스케일로 변환\n",
    "            image = np.array(image)  # 다시 NumPy 배열로 변환\n",
    "\n",
    "        # NumPy 배열을 텐서로 변환\n",
    "        image = torch.tensor(image, dtype=torch.float32).unsqueeze(0)  # (H, W) -> (1, H, W)로 변경\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Albumentations 데이터 증강 정의\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    # A.ToGray(always_apply=True, p=1.0),  # 이미지를 그레이스케일로 변환\n",
    "    A.CLAHE(always_apply=False, p=1.0, clip_limit=(1, 18), tile_grid_size=(29, 1)),\n",
    "    A.Blur(always_apply=False, p=1.0, blur_limit=(3, 7)),\n",
    "    A.Downscale(always_apply=False, p=1.0, scale_min=0.1, scale_max=0.8),\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,))  # 정규화\n",
    "])\n",
    "\n",
    "# 검증 및 테스트 변환 (데이터 증강 없음)\n",
    "val_test_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    # A.ToGray(always_apply=True, p=1.0),  # 이미지를 그레이스케일로 변환\n",
    "    A.Normalize(mean=(0.5,), std=(0.5,))  # 정규화\n",
    "])\n",
    "\n",
    "# 학습 데이터셋 생성\n",
    "full_train_dataset = ImageDataset(train_df, transform=train_transform)\n",
    "\n",
    "# 학습 데이터셋과 검증 데이터셋으로 나누기 (80% train, 20% validation)\n",
    "train_size = int(0.8 * len(full_train_dataset))\n",
    "val_size = len(full_train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_train_dataset, [train_size, val_size])\n",
    "\n",
    "# 검증 데이터셋 변환 적용\n",
    "val_dataset.dataset.transform = val_test_transform\n",
    "\n",
    "# 테스트 데이터셋 생성\n",
    "test_dataset = ImageDataset(test_df, transform=val_test_transform)\n",
    "\n",
    "# 데이터로더 생성\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.2287, Train Accuracy: 0.9101, Validation Loss: 0.3165, Validation Accuracy: 0.8707\n",
      "Epoch 2, Train Loss: 0.1141, Train Accuracy: 0.9602, Validation Loss: 0.1886, Validation Accuracy: 0.9330\n",
      "Epoch 3, Train Loss: 0.0553, Train Accuracy: 0.9801, Validation Loss: 0.7119, Validation Accuracy: 0.8372\n",
      "Epoch 4, Train Loss: 0.0349, Train Accuracy: 0.9892, Validation Loss: 0.2875, Validation Accuracy: 0.9291\n",
      "Epoch 5, Train Loss: 0.0462, Train Accuracy: 0.9849, Validation Loss: 0.3026, Validation Accuracy: 0.9234\n",
      "Epoch 6, Train Loss: 0.0355, Train Accuracy: 0.9885, Validation Loss: 0.2920, Validation Accuracy: 0.9224\n",
      "Epoch 7, Train Loss: 0.0269, Train Accuracy: 0.9897, Validation Loss: 0.5434, Validation Accuracy: 0.8937\n",
      "Epoch 8, Train Loss: 0.0141, Train Accuracy: 0.9962, Validation Loss: 0.3101, Validation Accuracy: 0.9262\n",
      "Epoch 9, Train Loss: 0.0208, Train Accuracy: 0.9911, Validation Loss: 0.6370, Validation Accuracy: 0.8841\n",
      "Epoch 10, Train Loss: 0.0221, Train Accuracy: 0.9923, Validation Loss: 0.2755, Validation Accuracy: 0.9301\n",
      "Epoch 11, Train Loss: 0.0197, Train Accuracy: 0.9923, Validation Loss: 0.2155, Validation Accuracy: 0.9444\n",
      "Epoch 12, Train Loss: 0.0099, Train Accuracy: 0.9969, Validation Loss: 0.3134, Validation Accuracy: 0.9282\n",
      "Epoch 13, Train Loss: 0.0071, Train Accuracy: 0.9978, Validation Loss: 0.3067, Validation Accuracy: 0.9339\n",
      "Epoch 14, Train Loss: 0.0106, Train Accuracy: 0.9954, Validation Loss: 0.3089, Validation Accuracy: 0.9377\n",
      "Epoch 15, Train Loss: 0.0182, Train Accuracy: 0.9940, Validation Loss: 0.2916, Validation Accuracy: 0.9339\n",
      "Epoch 16, Train Loss: 0.0105, Train Accuracy: 0.9952, Validation Loss: 0.3044, Validation Accuracy: 0.9301\n",
      "Epoch 17, Train Loss: 0.0107, Train Accuracy: 0.9962, Validation Loss: 0.3700, Validation Accuracy: 0.9262\n",
      "Epoch 18, Train Loss: 0.0213, Train Accuracy: 0.9942, Validation Loss: 0.2566, Validation Accuracy: 0.9282\n",
      "Epoch 19, Train Loss: 0.0080, Train Accuracy: 0.9981, Validation Loss: 0.3396, Validation Accuracy: 0.9253\n",
      "Epoch 20, Train Loss: 0.0046, Train Accuracy: 0.9983, Validation Loss: 0.2850, Validation Accuracy: 0.9464\n",
      "Epoch 21, Train Loss: 0.0089, Train Accuracy: 0.9978, Validation Loss: 0.4135, Validation Accuracy: 0.9023\n",
      "Epoch 22, Train Loss: 0.0167, Train Accuracy: 0.9942, Validation Loss: 0.5397, Validation Accuracy: 0.9042\n",
      "Epoch 23, Train Loss: 0.0123, Train Accuracy: 0.9962, Validation Loss: 0.2905, Validation Accuracy: 0.9320\n",
      "Epoch 24, Train Loss: 0.0079, Train Accuracy: 0.9978, Validation Loss: 0.4252, Validation Accuracy: 0.9023\n",
      "Epoch 25, Train Loss: 0.0041, Train Accuracy: 0.9983, Validation Loss: 0.6032, Validation Accuracy: 0.9195\n",
      "Epoch 26, Train Loss: 0.0078, Train Accuracy: 0.9976, Validation Loss: 0.3945, Validation Accuracy: 0.9320\n",
      "Epoch 27, Train Loss: 0.0284, Train Accuracy: 0.9914, Validation Loss: 0.3143, Validation Accuracy: 0.9100\n",
      "Epoch 28, Train Loss: 0.0174, Train Accuracy: 0.9945, Validation Loss: 0.2430, Validation Accuracy: 0.9358\n",
      "Epoch 29, Train Loss: 0.0103, Train Accuracy: 0.9966, Validation Loss: 0.5002, Validation Accuracy: 0.9167\n",
      "Epoch 30, Train Loss: 0.0159, Train Accuracy: 0.9950, Validation Loss: 0.3852, Validation Accuracy: 0.9291\n",
      "Epoch 31, Train Loss: 0.0104, Train Accuracy: 0.9969, Validation Loss: 0.3847, Validation Accuracy: 0.9301\n",
      "Epoch 32, Train Loss: 0.0146, Train Accuracy: 0.9957, Validation Loss: 0.2640, Validation Accuracy: 0.9425\n",
      "Epoch 33, Train Loss: 0.0140, Train Accuracy: 0.9957, Validation Loss: 0.3039, Validation Accuracy: 0.9339\n",
      "Epoch 34, Train Loss: 0.0057, Train Accuracy: 0.9983, Validation Loss: 0.4230, Validation Accuracy: 0.9224\n",
      "Epoch 35, Train Loss: 0.0068, Train Accuracy: 0.9978, Validation Loss: 0.3005, Validation Accuracy: 0.9262\n",
      "Epoch 36, Train Loss: 0.0038, Train Accuracy: 0.9988, Validation Loss: 0.4394, Validation Accuracy: 0.9282\n",
      "Epoch 37, Train Loss: 0.0018, Train Accuracy: 0.9993, Validation Loss: 0.3620, Validation Accuracy: 0.9301\n",
      "Epoch 38, Train Loss: 0.0048, Train Accuracy: 0.9986, Validation Loss: 0.3540, Validation Accuracy: 0.9262\n",
      "Epoch 39, Train Loss: 0.0070, Train Accuracy: 0.9986, Validation Loss: 0.3988, Validation Accuracy: 0.9349\n",
      "Epoch 40, Train Loss: 0.0065, Train Accuracy: 0.9976, Validation Loss: 0.3586, Validation Accuracy: 0.9272\n"
     ]
    }
   ],
   "source": [
    "# 이진 분류 모델 정의\n",
    "class BinaryClassificationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BinaryClassificationModel, self).__init__()\n",
    "        self.layer_1 = nn.Linear(256 * 256, 128)  # 입력 크기 256*256에 맞게 설정\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.layer_2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.layer_3 = nn.Linear(64, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # 입력을 평탄화\n",
    "        x = self.layer_1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.layer_2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = torch.relu(x)\n",
    "        z = self.layer_3(x)\n",
    "        return z\n",
    "\n",
    "# 모델 인스턴스 생성\n",
    "model = BinaryClassificationModel()\n",
    "\n",
    "# GPU 사용 설정 \"cuda\" if torch.cuda.is_available() else \n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "loss_function = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 모델 학습 루프\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # 옵티마이저 초기화\n",
    "        outputs = model(images)  # 모델 예측\n",
    "        loss = loss_function(outputs, labels)  # 손실 계산\n",
    "        loss.backward()  # 역전파\n",
    "        optimizer.step()  # 가중치 업데이트\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # 정확도 계산\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  # 로짓을 확률로 변환하고 이진 클래스로 변환\n",
    "        total += labels.size(0)  # 총 레이블 수\n",
    "        correct += (predicted == labels).sum().item()  # 정확한 예측의 개수\n",
    "\n",
    "    train_accuracy = correct / total  # 학습 정확도 계산\n",
    "\n",
    "    # 검증 단계\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "            outputs = model(images)\n",
    "            loss = loss_function(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # 정확도 계산\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    val_accuracy = val_correct / val_total  # 검증 정확도 계산\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Train Loss: {epoch_loss / len(train_loader):.4f}, \"\n",
    "          f\"Train Accuracy: {train_accuracy:.4f}, \"\n",
    "          f\"Validation Loss: {val_loss / len(val_loader):.4f}, \"\n",
    "          f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습만 gpu, 계산은 cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 2.4770, Test Accuracy: 0.7734\n"
     ]
    }
   ],
   "source": [
    "# 모델 평가 및 예측\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "total = 0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        # GPU로 데이터 이동\n",
    "        images, labels = images.to(device), labels.float().unsqueeze(1).to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = loss_function(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        \n",
    "        # 0.5 기준으로 이진 분류\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  \n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy().flatten())\n",
    "        \n",
    "        # 정확도 계산\n",
    "        total += labels.size(0)  # 총 레이블 수\n",
    "        correct += (predicted == labels).sum().item()  # 정확한 예측의 개수\n",
    "\n",
    "# 최종 테스트 손실 및 정확도 출력\n",
    "test_accuracy = correct / total  # 테스트 정확도 계산\n",
    "print(f\"Test Loss: {test_loss / len(test_loader):.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      NORMAL       0.91      0.45      0.60       242\n",
      "   PNEUMONIA       0.74      0.97      0.84       398\n",
      "\n",
      "    accuracy                           0.77       640\n",
      "   macro avg       0.83      0.71      0.72       640\n",
      "weighted avg       0.81      0.77      0.75       640\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 분류 레포트 출력\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "class_labels = ['NORMAL', 'PNEUMONIA']\n",
    "report = classification_report(all_labels, all_predictions, target_names=class_labels)\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aug_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
