{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywURY0wd9nAj"
      },
      "source": [
        "### **1. 활성화 함수가 ReLU인 이층 신경망이 dictionary로 주어져 있다.**\n",
        "$$\n",
        "\\{W_1 : \\begin{bmatrix} 0&0&0&0&1 \\\\ -1&0&0&0&0 \\\\ 0&-1&0&0&0 \\\\ 0&0&-1&0&0 \\\\ 0&0&0&-1&0 \\end{bmatrix},~\n",
        "b_1 : [5,4,3,2,1],~\n",
        "W_2 : \\begin{bmatrix} 0&1&0&0&0 \\\\ 0&0&1&0&0 \\\\ 0&0&0&1&0 \\\\ 0&0&0&0&1 \\\\ 1&0&0&0&0 \\end{bmatrix},~\n",
        "b_2 : [-1,-2,0,0,0]\n",
        "\\}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RbcHynP39nAn"
      },
      "source": [
        "#### **(i) 3개의 데이터 [1,2,3,4,5], [2,3,4,5,6], [3,4,5,6,7]에 대하여 한번에 배치처리로 계산하여 소프트맥스(softmax)값을 구하시오.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaPGlj7p9nAo"
      },
      "source": [
        "첫번째 Affine층을 통과시키면\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&\n",
        "\\begin{pmatrix}\n",
        "1&2&3&4&5\\\\\n",
        "2&3&4&5&6\\\\\n",
        "3&4&5&6&7\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix} 0&0&0&0&1 \\\\ -1&0&0&0&0 \\\\ 0&-1&0&0&0 \\\\ 0&0&-1&0&0 \\\\ 0&0&0&-1&0 \\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "5&4&3&2&1\n",
        "\\end{pmatrix}\\\\\n",
        "=&\n",
        "\\begin{pmatrix}\n",
        "-2&-3&-4&-5&1\\\\\n",
        "-3&-4&-5&-6&2\\\\\n",
        "-4&-5&-6&-7&3\n",
        "\\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "5&4&3&2&1\n",
        "\\end{pmatrix}\\\\\n",
        "=&\n",
        "\\begin{pmatrix}\n",
        "3&1&-1&-3&2\\\\\n",
        "2&0&-2&-4&3\\\\\n",
        "1&-1&-3&-5&4\n",
        "\\end{pmatrix}\n",
        "\\end{aligned}\n",
        "$$\n",
        "입니다.\n",
        "덧셈은 브로드캐스팅 개념으로 이해하세요.\n",
        "은닉층에서 ReLU 함수를 좌표별로 적용하면 음수가 죽게 되어\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "3&1&0&0&2\\\\\n",
        "2&0&0&0&3\\\\\n",
        "1&0&0&0&4\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "가 나옵니다.\n",
        "두번째 Affine층을 통과시키면\n",
        "$$\n",
        "\\begin{aligned}\n",
        "&\n",
        "\\begin{pmatrix}\n",
        "3&1&0&0&2\\\\\n",
        "2&0&0&0&3\\\\\n",
        "1&0&0&0&4\n",
        "\\end{pmatrix}\n",
        "\\begin{pmatrix} 0&1&0&0&0 \\\\ 0&0&1&0&0 \\\\ 0&0&0&1&0 \\\\ 0&0&0&0&1 \\\\ 1&0&0&0&0 \\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "-1&-2&0&0&0\n",
        "\\end{pmatrix}\\\\\n",
        "=&\n",
        "\\begin{pmatrix}\n",
        "2&3&1&0&0\\\\\n",
        "3&2&0&0&0\\\\\n",
        "4&1&0&0&0\n",
        "\\end{pmatrix}\n",
        "+\n",
        "\\begin{pmatrix}\n",
        "-1&-2&0&0&0\n",
        "\\end{pmatrix}\\\\\n",
        "=&\n",
        "\\begin{pmatrix}\n",
        "1&1&1&0&0\\\\\n",
        "2&0&0&0&0\\\\\n",
        "3&-1&0&0&0\n",
        "\\end{pmatrix}\n",
        "\\end{aligned}\n",
        "$$\n",
        "입니다.\n",
        "마지막으로 소프트맥스 변환을 합니다. 먼저 $e^x$을 적용하면\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "e&e&e&1&1\\\\\n",
        "e^2&1&1&1&1\\\\\n",
        "e^3&e^{-1}&1&1&1\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "이고 노멀라이즈하면\n",
        "$$\n",
        "\\begin{pmatrix}\n",
        "{e \\over 3e+2}&{e \\over 3e+2}&{e \\over 3e+2}&{1 \\over 3e+2}&{1 \\over 3e+2}\\\\\n",
        "{e^2 \\over e^2+4}&{1 \\over e^2+4}&{1 \\over e^2+4}&{1 \\over e^2+4}&{1 \\over e^2+4}\\\\\n",
        "{e^3 \\over e^3+e^{-1}+3} & {e^{-1} \\over e^3+e^{-1}+3} & {1 \\over e^3+e^{-1}+3} & {1 \\over e^3+e^{-1}+3} & {1 \\over e^3+e^{-1}+3}\n",
        "\\end{pmatrix}\n",
        "$$\n",
        "를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6EbVXoKg9nAp"
      },
      "source": [
        "#### **(ii) forward.py를 수정하여 구현하세요.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obZrwTHX9nAq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x.T\n",
        "        x = x - np.max(x, axis=0)\n",
        "        y = np.exp(x) / np.sum(np.exp(x), axis=0)\n",
        "        return y.T\n",
        "\n",
        "    x = x - np.max(x) # 오버플로 대책\n",
        "    return np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "def init_network():\n",
        "    network = {}\n",
        "    network['W1'] = np.array([[0,0,0,0,1],[-1,0,0,0,0],[0,-1,0,0,0],[0,0,-1,0,0],[0,0,0,-1,0]])\n",
        "    network['b1'] = np.array([5,4,3,2,1])\n",
        "    network['W2'] = np.array([[0,1,0,0,0],[0,0,1,0,0],[0,0,0,1,0],[0,0,0,0,1],[1,0,0,0,0]])\n",
        "    network['b2'] = np.array([-1,-2,0,0,0])\n",
        "\n",
        "    return network\n",
        "\n",
        "def forward(network, x):\n",
        "\n",
        "\n",
        "    return y\n",
        "\n",
        "network = init_network()\n",
        "x = np.array([[1,2,3,4,5],[2,3,4,5,6],[3,4,5,6,7]])\n",
        "y = forward(network, x)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dp7QW_kD9nAs"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append('C:/Users/user/Downloads/deep-learning-from-scratch-master/') # 각자의 경로로 수정해주세요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A2lYd0bb9nAs"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "from dataset.mnist import load_mnist\n",
        "from common.functions import sigmoid, softmax\n",
        "\n",
        "\n",
        "def get_data():\n",
        "    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)\n",
        "    return x_test, t_test\n",
        "\n",
        "\n",
        "def init_network():\n",
        "    with open('C:/Users/user/Downloads/deep-learning-from-scratch-master/ch03/sample_weight.pkl', 'rb') as f: # 각자의 경로로 수정해주세요.\n",
        "        network = pickle.load(f)\n",
        "    return network\n",
        "\n",
        "\n",
        "def predict(network, x):\n",
        "    w1, w2, w3 = network['W1'], network['W2'], network['W3']\n",
        "    b1, b2, b3 = network['b1'], network['b2'], network['b3']\n",
        "\n",
        "    a1 = np.dot(x, w1) + b1\n",
        "    z1 = sigmoid(a1)\n",
        "    a2 = np.dot(z1, w2) + b2\n",
        "    z2 = sigmoid(a2)\n",
        "    a3 = np.dot(z2, w3) + b3\n",
        "    y = softmax(a3)\n",
        "\n",
        "    return y\n",
        "\n",
        "\n",
        "x, t = get_data()\n",
        "network = init_network()\n",
        "\n",
        "batch_size = 100 # 배치 크기\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "    x_batch = x[i:i+batch_size]\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Tw_xvOq9nAt"
      },
      "source": [
        "학습을 위해 28×28 이미지를 flatten해서 784차원 벡터로 변환했습니다.  \n",
        "테스트 데이터는 모두 10,000장이므로 입력 데이터는 10000×784 행렬입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pcgAEPIA9nAt"
      },
      "outputs": [],
      "source": [
        "print(x.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGLLk_cI9nAu"
      },
      "source": [
        "100장씩 묶어 배치처리를 합니다.  \n",
        "한번에 100×784 행렬이 입력됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KAdmXZYy9nAu"
      },
      "outputs": [],
      "source": [
        "print(x_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XqqJLk9nAu"
      },
      "source": [
        "Affine 변환 → Sigmoid 변환 → Affine 변환 → Sigmoid 변환 → Affine 변환 → Softmax변환을 거쳐 마지막에는 10차원 확률벡터가 출력됩니다.  \n",
        "100장씩 묶어서 배치처리를 하므로 각 행이 확률벡터인 100×10 행렬이 출력됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SGg9qwK9nAv"
      },
      "outputs": [],
      "source": [
        "print(y_batch.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b22tNkAX9nAv"
      },
      "source": [
        "각 행이 확률벡터인 100×10 행렬을 모두 더하면 100입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFX8nUQi9nAv"
      },
      "outputs": [],
      "source": [
        "print(np.sum(y_batch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rlmd5ww9nAv"
      },
      "source": [
        "100×10 행렬에서 각 행의 최대 확률 위치를 모으면 p입니다.  \n",
        "p는 0부터 9까지 정수로 이루어진 100차원 벡터입니다.  \n",
        "신경망이 배치데이터에 대해 예측한 답을 모아놓은 리스트로 이해할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZVgrRyN9nAw"
      },
      "outputs": [],
      "source": [
        "print(p.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lbzQdSQ9nAw"
      },
      "source": [
        "### neuralnet_mnist_batch.py를 수정해서 가중치 행렬을 표준정규분포를 따라 랜덤하게 선택하고 편향 벡터는 제로 벡터로 놓고 정확도를 측정하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eISD3vYT9nAw"
      },
      "source": [
        "np.random.randn과 np.zeors를 이용해 가중치 행렬과 편향벡터를 생성합니다.\n",
        "가중치를 랜덤하게 생성했기 때문에 신경망의 예측은 그냥 찍는 거나 다름없습니다.\n",
        "10지선다 문제를 찍는 상황이라 정답률은 대략 10프로정도 나옵니다.\n",
        "실행할때마다 랜덤하게 가중치를 새로 생성하기 때문에 약간씩 달라집니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WTgkFsAY9nAw"
      },
      "outputs": [],
      "source": [
        "def random_init_network():\n",
        "    network = {}\n",
        "    network['W1'] = np.random.randn(784,50)\n",
        "    network['b1'] = np.zeros(50)\n",
        "    network['W2'] = np.random.randn(50,100)\n",
        "    network['b2'] = np.zeros(100)\n",
        "    network['W3'] = np.random.randn(100,10)\n",
        "    network['b3'] = np.zeros(10)\n",
        "    return network\n",
        "\n",
        "network = random_init_network()\n",
        "\n",
        "batch_size = 100 # 배치 크기\n",
        "accuracy_cnt = 0\n",
        "\n",
        "for i in range(0, len(x), batch_size):\n",
        "    x_batch = x[i:i+batch_size]\n",
        "    y_batch = predict(network, x_batch)\n",
        "    p = np.argmax(y_batch, axis=1)\n",
        "    accuracy_cnt += np.sum(p == t[i:i+batch_size])\n",
        "\n",
        "print(\"Accuracy:\" + str(float(accuracy_cnt) / len(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyGCd0Q39nAx"
      },
      "source": [
        "### neuralnet_mnist_batch.py를 수정해서 배치크기를 1,2,3,...,30으로 잡았을때 각각 걸리는 시간을 측정해서 그래프로 표시하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5_gkJIM9nAx"
      },
      "source": [
        "batch_size를 100에서 [1,2,3,...,30]으로 바꾸고 각 배치 크기에 대해서 신경망의 처리 시간을 담을 빈 리스트 elapse를 만듭니다.\n",
        "반복문으로 각 배치 크기에 대해 시간을 측정해 elapse에 기록합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxKE8Yu_9nAx"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "network = init_network()\n",
        "\n",
        "batch_size = np.arange(1,31) # 배치 크기\n",
        "elapse = []\n",
        "\n",
        "for k in batch_size:\n",
        "    accuracy_cnt = 0\n",
        "    start=time.time()\n",
        "    for i in range(0, len(x), k):\n",
        "        x_batch = x[i:i+k]\n",
        "        y_batch = predict(network, x_batch)\n",
        "        p = np.argmax(y_batch, axis=1)\n",
        "        accuracy_cnt += np.sum(p == t[i:i+k])\n",
        "    elapse.append(time.time()-start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FD0KXleW9nAx"
      },
      "source": [
        "배치크기가 1일때와 30일때는 무려 10배의 속도 차이가 있네요.\n",
        "데이터 처리양은 10,000장으로 동일하지만 배치크기가 1일때는 10,000번 액세스를 하고 배치크기가 30일때는 334번 액세스하기 때문에 그렇습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ckl08HJZ9nAy"
      },
      "outputs": [],
      "source": [
        "print(elapse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITrhGWcH9nAy"
      },
      "source": [
        "그래프로 시각화 해보죠."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-0sgEQL9nAy"
      },
      "outputs": [],
      "source": [
        "plt.plot(batch_size,elapse)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuwAJyJL9nAy"
      },
      "source": [
        "###  neuralnet mnist error.py를 수정해서 다음에 답하시오"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxmvKFem9nAy"
      },
      "source": [
        "#### **(i) 신경망이 90프로 이상의 확신을 가지고 맞춘 이미지가 몇 프로인지 구하고 첫 25장의 이미지를 5 X 5 테이블로 출력하시오.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuLmLXhC9nAz"
      },
      "source": [
        "맞춰야 하니까 p==t[i]로 수정하고 90프로 이상으로 예측해야 하므로 y[p]>0.9란 조건을 추가합니다.\n",
        "조건이 두개 이상일 경우는 &로 연결합니다.\n",
        "정확도가 93.52프로인데 75.19프로가 나왔기때문에 신경망이 맞출때 아리송하게 맞춘 데이터보다는 확신에 차서 맞춘 데이터가 훨씬 많다는 것을 알수 있네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc-gtcWz9nAz"
      },
      "outputs": [],
      "source": [
        "confident=[]\n",
        "\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "    if (p == t[i]) & (y[p]>0.9):\n",
        "        confident.append(i)\n",
        "\n",
        "print(len(confident)/len(x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb99RBah9nAz"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x[confident[i]].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(str(t[confident[i]]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GuGPZJF49nAz"
      },
      "source": [
        "#### **(ii) 신경망이 50프로 미만의 아리송하게 맞춘 이미지가 몇프로 인지 구하고 첫 25장의 이미지를 5 X 5 테이블로 출력하시오.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5gF9R0f9nA0"
      },
      "source": [
        "여전히 맞추니까 p==t[i]는 그대로 두고 50프로 미만으로 예측해야 하므로 y[p]<0.5로 수정합니다.\n",
        "정확도가 93.52프로인데 1.37프로가 나왔기때문에 신경망이 아리송하게 맞춘 데이터는 매우 적다는 것을 알수 있네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VwPtjRva9nA0"
      },
      "outputs": [],
      "source": [
        "arikari=[]\n",
        "\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "    if (p == t[i]) & (y[p]<0.5):\n",
        "        arikari.append(i)\n",
        "\n",
        "print(len(arikari)/len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ATnPI8S9nA0"
      },
      "source": [
        "악필이 많아서 신경망이 혼동할만 하네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMXNexg49nA0"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x[arikari[i]].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(str(t[arikari[i]]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHUVdXUg9nA1"
      },
      "source": [
        "#### (iii) 신경망이 90프로 이상의 확신을 가지고 대답했으나 틀린 이미지가 몇프로 인지 구하고 첫 25장의 이미지를 5 X 5 테이블로 출력하시오. 이미지 밑 라벨 옆에 신경망이 답한 숫자도 표시하시오."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSdyVuFK9nA2"
      },
      "source": [
        "틀렸으니까 p!=t[i]로 수정하고 90프로 이상으로 예측해야 하므로 y[p]>0.9로 수정합니다. 오류율이 6.48프로인데 0.53프로가 나왔기때문에 신경망이 확신에 차서 대답했음에도 틀린 문제는 오류율의 10프로정도를 차지한다고 볼수 있겠네요.\n",
        "신경망이 답한 숫자도 표시해야 하므로 빈 리스트를 만들고 반복문을 통해 신경망이 답한 숫자도 채워 넣습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koka7Uo89nA2"
      },
      "outputs": [],
      "source": [
        "sakura=[]\n",
        "answer=[]\n",
        "for i in range(len(x)):\n",
        "    y = predict(network, x[i])\n",
        "    p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "    if (p != t[i]) & (y[p]>0.9):\n",
        "        sakura.append(i)\n",
        "        answer.append(p)\n",
        "\n",
        "print(len(sakura)/len(x))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvtAuaQD9nA2"
      },
      "source": [
        "신경망이 왜 착각을 했을까요? 제 해석은 다음과 같습니다.\n",
        "\n",
        "5→6 : 5의 아래획을 둥글게 감음\n",
        "\n",
        "6→0 : 윗 획이 짧아서 0으로 착각한듯 합니다.\n",
        "\n",
        "4→9 : 오른쪽 획이 짧아서 9로 착각한듯 합니다.\n",
        "\n",
        "4→6 : 오른쪽과 아래 획이 뭉게져서 6으로 착각한듯합니다.\n",
        "\n",
        "3→8 : 아래 획이 붙어서 8로 착각한듯 합니다.\n",
        "\n",
        "7→2 : 서양인들은 7을 쓸때 획을 긋는 경우가 많습니다. 2의 아래획으로 착각한듯합니다.\n",
        "\n",
        "7→1 : 세로획에 비해 가로획들이 너무 짧아 7로 착각한듯 합니다.\n",
        "\n",
        "3→7 : 중간부분의 변곡이 너무 적어서 7로 착각한듯 합니다.\n",
        "\n",
        "9→3 : 윗 획이 감겨있지 않아 4로 착각한듯 합니다.\n",
        "\n",
        "2→0 : 아래 획이 너무 짧아 0으로 착각한 듯 합니다.\n",
        "\n",
        "3→2 : 아래 획이 너무 짧아 2로 착각한듯 합니다.\n",
        "\n",
        "인공신경망이 인간처럼 지능을 가지고 있는지 아니면 정교한 계산기일 뿐인지에 대한 논쟁이 있습니다.\n",
        "구성만 보면 인공신경망은 입력된 벡터를 Affine 변환 Sigmoid 변환을 번갈아 적용한후 마지막에 softmax변환으로 확률벡터를 출력해내는 고도의 계산기일뿐입니다. 하지만 인공신경망이 하는 착각을 보면 인간도 공감할수 있는 자연스러운 면이 있습니다. 마치 지능처럼 보이지요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI36ydsq9nA2"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(25):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(x[sakura[i]].reshape(28,28), cmap=plt.cm.binary)\n",
        "    plt.xlabel(str(t[sakura[i]])+'→'+str(answer[i]))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7euiLXx39nA3"
      },
      "source": [
        "### **6. (i) MNIST imshow.py를 수정하여 노멀라이즈한 MNIST 테스트 데이터에 평균은 0이고 표준편차는 $\\sigma$인 정규분포를 따라 노이즈를 줘서 다음과 같이 각각 출력하시오. ($\\sigma=0.1,0.2,0.5$)**\n",
        "![image-3.png](attachment:image-3.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fdlMKbEC9nA3"
      },
      "source": [
        "현실에서는 노이즈가 섞이게 마련입니다.\n",
        "i번째 테스트 데이터 x_test[i][0]에 std * np.random.randn(28,28)을 더함으로써 MNIST 이미지에 노이즈를 섞어줍니다.\n",
        "표준정규분포에 std를 곱하면 표준편차가 std가 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BEDwkh_c9nA3"
      },
      "outputs": [],
      "source": [
        "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False, normalize=True)\n",
        "\n",
        "for std in (0.1,0.2,0.5):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    for i in range(25):\n",
        "        plt.subplot(5,5,i+1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.imshow(x_test[i][0] + std * np.random.randn(28,28), cmap=plt.cm.binary)\n",
        "        plt.xlabel(t_test[i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RP45wPiw9nA3"
      },
      "source": [
        "#### **(ii) neuralnet_mnist.py를 수정해서 노멀라이즈한 MNIST 테스트 데이터에 평균은 0이고 표준편차는 $\\sigma$인 정규분포를 따라 노이즈를 줘서 각각 정확도를 구하시오. ($\\sigma=0.1,0.2,0.5$)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgS-yD2l9nA3"
      },
      "source": [
        "인공신경망이 노이즈에 대해 상당히 견고하네요."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpik38Zf9nA4"
      },
      "outputs": [],
      "source": [
        "for std in (0.1,0.2,0.5):\n",
        "    accuracy_cnt = 0\n",
        "    for i in range(len(x)):\n",
        "        y = predict(network, x[i] + std*np.random.randn(784))\n",
        "        p= np.argmax(y) # 확률이 가장 높은 원소의 인덱스를 얻는다.\n",
        "        if p == t[i]:\n",
        "            accuracy_cnt += 1\n",
        "\n",
        "    print(\"sigma=\"+str(std)+\" : \"+str(float(accuracy_cnt) / len(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4fmyRL29nA4"
      },
      "source": [
        "###  neuralnet_mnist_batch.py에 다음 코드를 추가하면 다음과 같은 10 X 10 행렬이 출력이 된다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xFI8t06k9nA4"
      },
      "outputs": [],
      "source": [
        "confusion = np.zeros((10,10), dtype=int)\n",
        "\n",
        "for k in range(len(x)):\n",
        "    i=int(t[k])\n",
        "    y = predict(network, x[k])\n",
        "    j= np.argmax(y)\n",
        "    confusion[i][j] += 1\n",
        "\n",
        "print(confusion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FSKdrGJ9nA4"
      },
      "source": [
        "**(i) 신경망이 4를 9라고 답한 횟수는?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWv0R3YR9nA5"
      },
      "source": [
        "confusion : 10$\\times$10 제로 행렬  \n",
        "i : k번째 데이터의 라벨  \n",
        "y : k번째 데이터를 신경망에 입력했을때 출력되는 확률벡터  \n",
        "j : y에서 제일 큰 확률의 인덱스, 다시말해 신경망이 k번째 데이터에 대해 대답한 숫자  \n",
        "confusion의 i행 j열에 1을 더해나갑니다. (행과 열은 0부터 셉니다.)  \n",
        "반복문이 끝나면 confusion의 i행 j열 원소는 라벨이 i인 데이터를 신경망이 j라고 답한 회수가 됩니다.  \n",
        "따라서, 4를 9라고 답한 회수는 4행 9열에 등장하는 숫자인 35가 됩니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFcuPrpT9nA5"
      },
      "source": [
        "**(iii) 다음 값을 출력하도록 코드를 추가하시오.\n",
        "$$\n",
        "\\text{신경망이 $4$라고 예측한 데이터중 실제 라벨이 $4$인 데이터의 수} \\over \\text{$4$라고 예측한 데이터의 수}\n",
        "$$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T8y8MEF-9nA5"
      },
      "outputs": [],
      "source": [
        "print(confusion[4,4]/np.sum(confusion[:,4]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjTy4nq79nA5"
      },
      "source": [
        "**(iv) 다음 값을 출력하도록 코드를 추가하시오.\n",
        "$$\n",
        "\\text{라벨이 $4$인 데이터중 신경망이 $4$라고 예측한 데이터의 수} \\over \\text{라벨이 $4$인 데이터의 수}\n",
        "$$**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wX8dKmfZ9nA6"
      },
      "outputs": [],
      "source": [
        "print(confusion[4,4]/np.sum(confusion[4,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5sJyPV-9nA6"
      },
      "source": [
        "#### 테스트 데이터 전체에 대하여 `predict`를 한 후 4를 9라고 답한 회수를 출력하시오. 반복문 대신 일괄처리로 코드를 작성하시오."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IHchhjRP9nA6"
      },
      "outputs": [],
      "source": [
        "y = predict(network, x)\n",
        "p =\n",
        "print(np.sum((t==4)&(p==9)))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}