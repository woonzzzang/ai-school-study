{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/downtown/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/downtown/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "검색어: gun\n",
      "Name: Nuclear Option, Recommendation Count: 1745.0, Similar Keywords: ['accurately', 'advanced', 'aerodynamic', 'affects'], Similarity Score: 0.5626903787551667\n",
      "Name: Wanderlost, Recommendation Count: 0.0, Similar Keywords: ['advanced', 'amass', 'america', 'apocalyptic', 'bad'], Similarity Score: 0.5483831629435686\n",
      "Name: Madden NFL 23, Recommendation Count: 4723.0, Similar Keywords: ['accurately', 'activities', 'add', 'addition'], Similarity Score: 0.5402115118454782\n",
      "Name: 不二臣The Only  Master, Recommendation Count: 0.0, Similar Keywords: ['bl游戏在国内真的好难', 'ps', 'resdiy素材自助生成平台', '一个he', '上架时间一再推迟'], Similarity Score: 0.5272921459301934\n",
      "Name: Legends of Astravia, Recommendation Count: 0.0, Similar Keywords: ['abilities', 'age', 'allows', 'arc'], Similarity Score: 0.5237884038914411\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sqlalchemy import create_engine\n",
    "import json\n",
    "\n",
    "# nltk 데이터 다운로드\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Supabase 데이터베이스 연결\n",
    "DATABASE_URL = \"postgresql://postgres.nhcmippskpgkykwsumqp:123$tiger_BJs@aws-0-ap-northeast-2.pooler.supabase.com:6543/postgres\"\n",
    "engine = create_engine(DATABASE_URL)\n",
    "\n",
    "# GloVe 벡터 로드\n",
    "glove_file = \"glove.6B.100d.txt\"\n",
    "embeddings_index = {}\n",
    "with open(glove_file, encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "# 벡터 생성 함수\n",
    "def get_vector(word):\n",
    "    return embeddings_index.get(word, np.zeros(100))\n",
    "\n",
    "# 문장 벡터 계산 함수\n",
    "def sentence_vector(sentence):\n",
    "    words = nltk.word_tokenize(sentence)\n",
    "    words = [word.lower() for word in words if word.isalnum()]\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    if len(words) == 0:\n",
    "        return np.zeros(100)\n",
    "    vectors = [get_vector(word) for word in words]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# 데이터베이스에서 벡터 로드\n",
    "vector_query = \"SELECT appid, embedding, name, recommendation_count, description_phrases, name_vector, genre_vector FROM steamsearcher_duplicate\"\n",
    "vector_df = pd.read_sql(vector_query, engine)\n",
    "\n",
    "# 벡터가 JSON 문자열인지 확인하고 변환\n",
    "def parse_embedding(embedding):\n",
    "    if isinstance(embedding, str):\n",
    "        return json.loads(embedding)\n",
    "    return embedding\n",
    "\n",
    "vector_df['embedding'] = vector_df['embedding'].apply(parse_embedding)\n",
    "vector_df['name_vector'] = vector_df['name_vector'].apply(lambda x: np.array(json.loads(x)))\n",
    "vector_df['genre_vector'] = vector_df['genre_vector'].apply(lambda x: np.array(json.loads(x)))\n",
    "\n",
    "# 모든 벡터가 동일한 크기인지 확인하고 None 값을 처리\n",
    "embedding_size = 100  # GloVe 벡터 크기와 일치시킴\n",
    "def check_and_fix_embedding(embedding):\n",
    "    if embedding is None or len(embedding) != embedding_size:\n",
    "        return np.zeros(embedding_size).tolist()\n",
    "    return embedding\n",
    "\n",
    "vector_df['embedding'] = vector_df['embedding'].apply(check_and_fix_embedding)\n",
    "\n",
    "# description_phrases가 JSON 문자열인지 확인하고 변환\n",
    "def parse_description_phrases(description_phrases):\n",
    "    if isinstance(description_phrases, str):\n",
    "        return json.loads(description_phrases)\n",
    "    return description_phrases\n",
    "\n",
    "vector_df['description_phrases'] = vector_df['description_phrases'].apply(parse_description_phrases)\n",
    "\n",
    "sentence_vectors = np.array(vector_df['embedding'].tolist())\n",
    "name_vectors = np.array(vector_df['name_vector'].tolist())\n",
    "genre_vectors = np.array(vector_df['genre_vector'].tolist())\n",
    "sentences = vector_df['description_phrases'].tolist()\n",
    "names = vector_df['name'].tolist()\n",
    "recommendation_counts = vector_df['recommendation_count'].tolist()\n",
    "\n",
    "# 검색어 입력 및 유사 문장 찾기\n",
    "def find_similar_sentences(query, top_n=5, weights=(0.5, 0.25, 0.25)):\n",
    "    query_vector = sentence_vector(query)\n",
    "    name_query_vector = sentence_vector(query)\n",
    "    genre_query_vector = sentence_vector(query)\n",
    "    \n",
    "    # 유사도 계산\n",
    "    description_similarities = cosine_similarity([query_vector], sentence_vectors)[0]\n",
    "    name_similarities = cosine_similarity([name_query_vector], name_vectors)[0]\n",
    "    genre_similarities = cosine_similarity([genre_query_vector], genre_vectors)[0]\n",
    "    \n",
    "    # 유사도 점수를 정규화\n",
    "    description_similarities = (description_similarities + 1) / 2\n",
    "    name_similarities = (name_similarities + 1) / 2\n",
    "    genre_similarities = (genre_similarities + 1) / 2\n",
    "    \n",
    "    # 가중치를 적용하여 최종 유사도 계산\n",
    "    final_similarities = (\n",
    "        weights[0] * description_similarities +\n",
    "        weights[1] * name_similarities +\n",
    "        weights[2] * genre_similarities\n",
    "    )\n",
    "    \n",
    "    sorted_indices = np.argsort(final_similarities)[::-1][:top_n]\n",
    "    results = []\n",
    "    for i in sorted_indices:\n",
    "        similar_keywords = [sentences[i][j] for j in range(min(5, len(sentences[i]))) if not sentences[i][j].isdigit()]\n",
    "        results.append({\n",
    "            'name': names[i],\n",
    "            'recommendation_count': recommendation_counts[i],\n",
    "            'similar_keywords': similar_keywords,\n",
    "            'similarity_score': final_similarities[i] * 100  # 퍼센트로 변환\n",
    "        })\n",
    "    return results\n",
    "\n",
    "# 검색어 입력 및 결과 출력\n",
    "query = input(\"검색어를 입력하세요: \")\n",
    "similar_sentences = find_similar_sentences(query)\n",
    "print(f\"검색어: {query}\")\n",
    "for result in similar_sentences:\n",
    "    print(f\"Name: {result['name']}, Recommendation Count: {result['recommendation_count']}, Similar Keywords: {result['similar_keywords']}, Similarity Score: {result['similarity_score']:.2f}%\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
