{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/downtown/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/downtown/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/downtown/nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from supabase import create_client, Client\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import json\n",
    "\n",
    "# 필수 구성 요소 초기화\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "punctuations = set(string.punctuation)\n",
    "\n",
    "# Supabase 클라이언트 초기화\n",
    "url = 'https://nhcmippskpgkykwsumqp.supabase.co'\n",
    "key = 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6Im5oY21pcHBza3Bna3lrd3N1bXFwIiwicm9sZSI6ImFub24iLCJpYXQiOjE3MjE2MjYyNzEsImV4cCI6MjAzNzIwMjI3MX0.quApu8EwzqcTgcxdWezDvpZIHSX9LKVQ_NytpLBeAiY' \n",
    "supabase: Client = create_client(url, key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most similar game: Birthday Boy and Benny (Similarity: 0.7332)\n",
      "Most similar keywords: ['friend (1.0000)', 'mother (0.7818)', 'mom (0.6288)', 'best (0.5370)', 'happy (0.5341)', 'birthday (0.4955)', 'therapist (0.4653)', 'year (0.3862)', 'party (0.3777)', 'sad (0.3364)']\n",
      "Most similar game: William's Love Prelude (Similarity: 0.7008)\n",
      "Most similar keywords: ['friend (1.0000)', 'man (0.7171)', 'boy (0.6790)', 'love (0.6468)', 'william (0.5418)', 'childhood (0.5393)', \"'s (0.5328)\", 'turn (0.4650)', 'strong (0.3895)', 'style (0.3430)']\n",
      "Most similar game: A Date for the Ages (Similarity: 0.6922)\n",
      "Most similar keywords: ['man (0.7171)', 'lady (0.5946)', 'alice (0.5712)', 'paul (0.5614)', 'divorced (0.4942)', 'things (0.4764)', 'pair (0.4564)', 'chair (0.3995)', 'herman (0.3365)', 'date (0.3336)']\n",
      "Most similar game: A World of Wishes (Similarity: 0.6920)\n",
      "Most similar keywords: ['father (0.8364)', 'mother (0.7818)', 'life (0.5967)', 'nicole (0.4809)', 'choice (0.4794)', 'murder (0.4757)', 'image (0.4034)', 'piece (0.3988)', 'truth (0.3936)', 'memory (0.3673)']\n",
      "Most similar game: NTRstory (Similarity: 0.6910)\n",
      "Most similar keywords: ['wife (0.8300)', 'husband (0.8268)', 'family (0.6281)', 'character (0.5844)', 'little (0.5446)', 'willing (0.4504)', 'sex (0.3924)', 'problem (0.3440)', 'happiness (0.3091)', 'path (0.3057)']\n",
      "Most similar game: Cute Socks (Similarity: 0.6907)\n",
      "Most similar keywords: ['friend (1.0000)', 'girl (0.6354)', 'life (0.5967)', 'thing (0.5424)', 'best (0.5370)', 'house (0.5077)', 'judy (0.4940)', 'julia (0.4780)', 'magazine (0.4211)', 'week (0.4182)']\n",
      "Most similar game: CALME (Similarity: 0.6905)\n",
      "Most similar keywords: ['father (0.8364)', 'son (0.7857)', 'boy (0.6790)', 'young (0.6273)', 'time (0.5435)', 'hunter (0.5272)', 'visit (0.4957)', 'join (0.4269)', 'tale (0.4169)', 'small (0.3896)']\n",
      "Most similar game: To Last (Similarity: 0.6850)\n",
      "Most similar keywords: ['father (0.8364)', 'family (0.6281)', 'character (0.5844)', 'reporter (0.5708)', 'story (0.5386)', 'walter (0.4939)', 'albert (0.4673)', 'attention (0.4499)', 'america (0.4449)', 'mysterious (0.4402)']\n",
      "Most similar game: My Furry Succubus 🐾 (Similarity: 0.6834)\n",
      "Most similar keywords: ['uncle (0.7771)', 'guy (0.6228)', 'old (0.5918)', 'story (0.5386)', 'wish (0.5215)', 'real (0.4710)', 'dinner (0.4634)', 'mysterious (0.4402)', 'new (0.4367)', 'fun (0.4178)']\n",
      "Most similar game: Gun Devil (Similarity: 0.6800)\n",
      "Most similar keywords: ['wife (0.8300)', 'son (0.7857)', 'love (0.6468)', 'personality (0.4500)', 'new (0.4367)', 'powerful (0.3801)', 'journey (0.3706)', 'foe (0.3522)', 'babe (0.3051)', 'weapon (0.2883)']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# GloVe 모델 로드 함수\n",
    "def load_glove_model(glove_file_path):\n",
    "    glove_model = {}\n",
    "    with open(glove_file_path, 'r', encoding='utf8') as f:\n",
    "        for line in f:\n",
    "            split_line = line.split()\n",
    "            word = split_line[0]\n",
    "            embedding = np.array([float(val) for val in split_line[1:]])\n",
    "            glove_model[word] = embedding\n",
    "    return glove_model\n",
    "\n",
    "# 텍스트 벡터화 함수 (KeyError 예외 처리 추가)\n",
    "def get_sentence_vector(sentence, glove_model, embedding_dim=100):\n",
    "    words = word_tokenize(sentence.lower())\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words and word not in punctuations]\n",
    "    word_vectors = []\n",
    "    for word in words:\n",
    "        try:\n",
    "            word_vectors.append(glove_model[word])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    # KeyError가 발생하면 단어를 무시하고 넘어갑니다.\n",
    "    if not word_vectors:\n",
    "        return np.zeros(embedding_dim)\n",
    "    return np.mean(word_vectors, axis=0)\n",
    "\n",
    "# 데이터베이스에서 검색 필드 데이터 가져오기 (SQL 쿼리 사용)\n",
    "def fetch_search_data():\n",
    "    response = supabase.table(\"steamsearcher_duplicate\").select(\"*\").execute()\n",
    "    data = response.data\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # 필터링 조건 적용\n",
    "    df = df[df['embedding'].notna() & df['name_embedding'].notna()]\n",
    "    \n",
    "    # JSON 문자열을 numpy 배열로 변환\n",
    "    df['embedding'] = df['embedding'].apply(lambda x: np.array(json.loads(x)) if x else np.zeros(100))\n",
    "    df['name_embedding'] = df['name_embedding'].apply(lambda x: np.array(json.loads(x)) if x else np.zeros(100))\n",
    "\n",
    "    return df\n",
    "\n",
    "# 유사도 계산 함수\n",
    "def find_most_similar_rows(query, glove_model, top_n=10):\n",
    "    df = fetch_search_data()\n",
    "    query_vector = get_sentence_vector(query, glove_model)\n",
    "    \n",
    "    def calculate_similarity(row):\n",
    "        row_vector = np.array(row['embedding'])\n",
    "        return cosine_similarity([query_vector], [row_vector])[0][0]\n",
    "    \n",
    "    df['similarity'] = df.apply(calculate_similarity, axis=1)\n",
    "    most_similar_rows = df.nlargest(top_n, 'similarity')\n",
    "    return most_similar_rows\n",
    "\n",
    "# 키워드 유사도 계산 함수\n",
    "def find_most_similar_keywords(query, row, glove_model, top_n=10):\n",
    "    query_vector = get_sentence_vector(query, glove_model)\n",
    "    keywords = ' '.join([str(row[field]) for field in ['name', 'genre', 'dp', 'summary', 'keyphrase'] if row[field]])\n",
    "    keyword_list = word_tokenize(keywords)\n",
    "    keyword_list = [word for word in keyword_list if word not in stop_words and word not in punctuations]\n",
    "    keyword_vectors = {word: glove_model[word] for word in keyword_list if word in glove_model}\n",
    "    \n",
    "    def calculate_keyword_similarity(word):\n",
    "        return cosine_similarity([query_vector], [keyword_vectors[word]])[0][0]\n",
    "    \n",
    "    if not keyword_vectors:\n",
    "        return []  # 키워드 벡터가 비어있을 경우 빈 리스트 반환\n",
    "\n",
    "    sorted_keywords = sorted(keyword_vectors.keys(), key=calculate_keyword_similarity, reverse=True)\n",
    "    sorted_keywords_with_scores = [(word, calculate_keyword_similarity(word)) for word in sorted_keywords]\n",
    "    return sorted_keywords_with_scores[:top_n]\n",
    "\n",
    "# 메인 함수 (유사도 검색)\n",
    "def main():\n",
    "    glove_file_path = 'glove.6B.100d.txt'\n",
    "    glove_model = load_glove_model(glove_file_path)\n",
    "    query = input(\"Enter your search query: \")\n",
    "    most_similar_rows = find_most_similar_rows(query, glove_model)\n",
    "    \n",
    "    for index, row in most_similar_rows.iterrows():\n",
    "        print(f\"Most similar game: {row['name']} (Similarity: {row['similarity']:.4f})\")\n",
    "        most_similar_keywords = find_most_similar_keywords(query, row, glove_model)\n",
    "        keywords_with_scores = [f\"{keyword} ({score:.4f})\" for keyword, score in most_similar_keywords]\n",
    "        print(f\"Most similar keywords: {keywords_with_scores}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snake",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
